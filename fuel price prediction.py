# -*- coding: utf-8 -*-
"""Copy of Yet another copy of testing experiments_ fuel price 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fEXj1igYnjsFqfduNqp30MYq3Y8t6Ndt

# **EXTRACT, LOAD DATA**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from keras.optimizers import Adam, Nadam, SGD, RMSprop
from sklearn.metrics import mean_squared_error, mean_absolute_error
from datetime import datetime
import requests
from tabulate import tabulate

# Load the dataset
url = 'https://docs.google.com/spreadsheets/d/1SnQdV18e9GjKfX5JXNv7mHXTIzVifrQZ5g0gSr4kWSc/export?format=csv'
data = pd.read_csv(url)
print(tabulate(data, headers='keys', tablefmt='pretty', showindex=False))

print(len(data))  # Total number of rows

"""# **PREPROCESSINGS:**
# 1. Handling Missing values
# 2. Normalization
# 3. Outlier detection
# 4. Stability / Stationary
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from statsmodels.tsa.stattools import adfuller
from tabulate import tabulate

# Replace empty strings with NaN
columns_to_clean = ['Gasoline\none week', 'Gasoline\nthree months', 'Diesel\none week', 'Diesel\nthree months']

for col in columns_to_clean:
    data[col].replace('', np.nan, inplace=True)

# Convert percentage values to numeric
def clean_percentage_column(column):
    column = column.replace('%', '', regex=True)  # Remove percentage symbols
    return pd.to_numeric(column, errors='coerce')  # Convert to numeric

for col in columns_to_clean:
    data[col] = np.log1p(clean_percentage_column(data[col]) / 100)  # log(1 + x)


# Handle missing values (fill using forward and backward fill)
data.fillna(method='ffill', limit=1, inplace=True)
data.fillna(method='bfill', limit=1, inplace=True)

# Drop remaining NaN values
data.dropna(inplace=True)

# Ensure there are no infinite values
data.replace([np.inf, -np.inf], np.nan, inplace=True)
data.dropna(inplace=True)

# Normalize features
scaler = MinMaxScaler(feature_range=(0, 1))
data[columns_to_clean] = scaler.fit_transform(data[columns_to_clean])

# Outlier detection using IQR method
def remove_outliers(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])
    df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])

for col in columns_to_clean:
    remove_outliers(data, col)

# Ensure final dataset has no NaNs or infinite values
data.replace([np.inf, -np.inf], np.nan, inplace=True)
data.dropna(inplace=True)

# Stationarity check using Augmented Dickey-Fuller test
def check_stationarity(series):
    if series.nunique() == 1:
        print(f"Skipping ADF test for '{series.name}' as it has constant values.\n")
        return

    result = adfuller(series)
    print(f'ADF Statistic for {series.name}: {result[0]:.4f}')
    print(f'p-value: {result[1]:.4f}')
    if result[1] < 0.05:
        print("Data is stationary.\n")
    else:
        print("Data is non-stationary. Differencing may be needed.\n")

for col in columns_to_clean:
    check_stationarity(data[col])

# Remove duplicates
data = data.drop_duplicates()

# Display processed data
print(tabulate(data, headers='keys', tablefmt='pretty', showindex=False))

data = data.sort_values(by=['Countries', 'Date']).reset_index(drop=True)
data['Gasoline\none week'] = data.groupby('Countries')['Gasoline\none week'].pct_change(periods=1)
data['Gasoline\nthree months'] = data.groupby('Countries')['Gasoline\nthree months'].pct_change(periods=1)
data['Diesel\none week'] = data.groupby('Countries')['Diesel\none week'].pct_change(periods=1)
data['Diesel\nthree months'] = data.groupby('Countries')['Diesel\nthree months'].pct_change(periods=1)
print(tabulate(data, headers='keys', tablefmt='pretty', showindex=False))

scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(data[['Gasoline\none week', 'Gasoline\nthree months', 'Diesel\none week', 'Diesel\nthree months']])  # Assign scaled_data here
print("Checking for NaN values in scaled_data:")
print(pd.DataFrame(scaled_data).isnull().sum())

scaled_data = pd.DataFrame(scaled_data).dropna().values  # Drop NaN rows

import numpy as np
from tabulate import tabulate
# Define the sequence length
sequence_length = 30
# Define the function to create sequences for LSTM input
def create_sequences(data, sequence_length=10):
    x, y = [], []
    for i in range(len(data) - sequence_length):
        x.append(data[i:i+sequence_length])
        y.append(data[i+sequence_length])
    return np.array(x), np.array(y)
y = scaled_data[:, 0]  # only one column
X, y = create_sequences(scaled_data, sequence_length)




X_df = pd.DataFrame(X.reshape(X.shape[0], -1))
y_df = pd.DataFrame(y)

print("X:\n", tabulate(X_df, headers='keys', tablefmt='pretty', showindex=False)) # print ALL rows
print("\ny:\n", tabulate(y_df, headers='keys', tablefmt='pretty', showindex=False)) # print ALL rows

##X: Contains sequences of values from the original time-series data. These sequences are the input to your LSTM network.
##y: Contains the values that follow each sequence in X. These are the targets that your LSTM network will try to predict.

"""# **MODELING**

# **MAIN MODELING**
"""

import math
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from sklearn.metrics import mean_squared_error, mean_absolute_error
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization, Bidirectional
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.losses import Huber
import os

# Handle missing values in the data
data = data.dropna()

# Get feature names for later use
feature_names = ['Gasoline\none week', 'Gasoline\nthree months', 'Diesel\none week', 'Diesel\nthree months']

# Sort data by country and date to ensure time order
data = data.sort_values(by=['Countries', 'Date']).reset_index(drop=True)

# IMPROVEMENT 1: Use per-country scaling
# Instead of scaling all countries together, scale each country separately
scaled_data = data.copy()
countries = data['Countries'].unique()
scalers = {}

for country in countries:
    country_mask = data['Countries'] == country
    country_data = data.loc[country_mask, feature_names]

    # Only create scaler if enough data
    if len(country_data) > 10:  # Arbitrary threshold
        scaler = StandardScaler()  # Use StandardScaler instead of MinMaxScaler
        scaled_values = scaler.fit_transform(country_data)
        scaled_data.loc[country_mask, feature_names] = scaled_values
        scalers[country] = scaler

# IMPROVEMENT 2: Use a longer sequence length
sequence_length = 12  # Increased from 4 to capture more temporal patterns

# Initialize containers
X, y = [], []
country_names = []
dates = []

# Create sequences PER country
for country in countries:
    country_data = scaled_data[scaled_data['Countries'] == country]
    values = country_data[feature_names].values

    # Skip countries with insufficient data points
    if len(values) <= sequence_length:
        continue

    # Store dates for later visualization
    country_dates = country_data['Date'].values

    for i in range(len(values) - sequence_length):
        seq = values[i:i+sequence_length]
        target = values[i+sequence_length]

        # Only add sequences and targets with no NaN values
        if not np.isnan(seq).any() and not np.isnan(target).any():
            X.append(seq)
            y.append(target)
            country_names.append(country)
            dates.append(country_dates[i+sequence_length])

# Convert to arrays
X = np.array(X)
y = np.array(y)
country_names = np.array(country_names)
dates = np.array(dates)

# Verify no NaN values in training data
assert not np.isnan(X).any(), "X still contains NaN values"
assert not np.isnan(y).any(), "y still contains NaN values"

# IMPROVEMENT 3: Use a time-based split instead of random
# Sort everything by date
sort_indices = np.argsort(dates)
X = X[sort_indices]
y = y[sort_indices]
country_names = country_names[sort_indices]
dates = dates[sort_indices]

# Define the split point (80% for training)
split_index = int(len(X) * 0.8)

# Perform the time series split
X_train = X[:split_index]
X_test = X[split_index:]
y_train = y[:split_index]
y_test = y[split_index:]
country_names_train = country_names[:split_index]
country_names_test = country_names[split_index:]
dates_train = dates[:split_index]
dates_test = dates[split_index:]

# IMPROVEMENT 4: Enhanced LSTM model with Bidirectional layers and BatchNormalization
def create_enhanced_lstm_model(input_shape, output_shape):
    model = Sequential()

    # First LSTM layer with more units
    model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=input_shape))
    model.add(BatchNormalization())
    model.add(Dropout(0.3))

    # Second LSTM layer
    model.add(Bidirectional(LSTM(64, return_sequences=True)))
    model.add(BatchNormalization())
    model.add(Dropout(0.3))

    # Third LSTM layer
    model.add(LSTM(32))
    model.add(BatchNormalization())
    model.add(Dropout(0.3))

    # Output layer with tanh activation for bounded output
    model.add(Dense(output_shape, activation='tanh'))

    return model

input_shape = (X_train.shape[1], X_train.shape[2])
output_shape = y_train.shape[1]
model = create_enhanced_lstm_model(input_shape, output_shape)

# IMPROVEMENT 5: Use a higher initial learning rate with decay
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss=Huber(delta=0.5),  # Reduced delta for Huber loss to be more sensitive to outliers
    metrics=['mae', 'mse', tf.keras.metrics.RootMeanSquaredError()]
)

model.summary()

# IMPROVEMENT 6: Enhanced callbacks
checkpoint_path = "fuel_price_model/cp.ckpt.weights.h5"  # Add '.weights.h5' to the filename
model_checkpoint = ModelCheckpoint(
    filepath=checkpoint_path,
    save_weights_only=True,
    monitor='val_loss',
    mode='min',
    save_best_only=True
)

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=5,  # Reduced patience
    restore_best_weights=True
)

lr_reduction = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.2,  # More aggressive reduction
    patience=3,  # Wait fewer epochs before reducing
    min_lr=0.00001,
    verbose=1
)

# IMPROVEMENT 7: Add class weights to handle imbalance if any
from sklearn.utils.class_weight import compute_sample_weight
sample_weights = compute_sample_weight(class_weight='balanced', y=np.argmax(y_train, axis=1) if y_train.shape[1] > 1 else y_train)

# Train the model
history = model.fit(
    X_train, y_train,
    epochs=150,  # Increased epochs since we have early stopping
    batch_size=32,
    validation_split=0.2,
    callbacks=[early_stopping, lr_reduction, model_checkpoint],
    verbose=1,
    sample_weight=sample_weights
)

# Evaluate the model
test_loss, test_mae, test_mse, test_rmse = model.evaluate(X_test, y_test, verbose=1)
print(f"Test MSE: {test_mse:.4f}, Test MAE: {test_mae:.4f}, Test RMSE: {test_rmse:.4f}")

# Make predictions
y_pred = model.predict(X_test)

# IMPROVEMENT 8: Inverse transform predictions for each country using the country-specific scaler
y_test_original = np.zeros_like(y_test)
y_pred_original = np.zeros_like(y_pred)

for i, country in enumerate(country_names_test):
    if country in scalers:
        y_test_original[i] = scalers[country].inverse_transform(y_test[i].reshape(1, -1))
        y_pred_original[i] = scalers[country].inverse_transform(y_pred[i].reshape(1, -1))

# Calculate metrics on the original scale
mse = mean_squared_error(y_test_original, y_pred_original)
mae = mean_absolute_error(y_test_original, y_pred_original)
rmse = math.sqrt(mse)
print(f"MSE on original scale: {mse:.4f}")
print(f"MAE on original scale: {mae:.4f}")
print(f"RMSE on original scale: {rmse:.4f}")

# Create a DataFrame to display the tabular results
def create_prediction_table(y_actual, y_predicted, countries, feature_names):
    results = []
    for i in range(len(y_actual)):
        row = {'Countries': countries[i]}  # Add country name
        for j, feature in enumerate(feature_names):
            row[f'{feature} (Actual %)'] = f"{y_actual[i, j]:.2f}%"
            row[f'{feature} (Predicted %)'] = f"{y_predicted[i, j]:.2f}%"
            row[f'{feature} (Error %)'] = f"{y_predicted[i, j] - y_actual[i, j]:.2f}%"
        results.append(row)
    return pd.DataFrame(results)

# Create and display prediction table (showing just first 10 rows for brevity)
countries = data['Countries'].iloc[split_index:]
prediction_table = create_prediction_table(y_test_original, y_pred_original, country_names_test, feature_names)
print("\nPredicted Fuel Price Changes (%)")
display(prediction_table)  # Changed display() to print() for wider compatibilit


# Function to plot predictions vs actual values with optional smoothing and zoom
def plot_predictions(y_actual, y_predicted, feature_names, title, smooth=True, zoom_last_n=100):
    plt.figure(figsize=(15, 10))

    for i in range(y_actual.shape[1]):
        plt.subplot(2, 2, i + 1)

        # Convert to pandas Series for smoothing
        actual_series = pd.Series(y_actual[:, i])
        predicted_series = pd.Series(y_predicted[:, i])

        # Apply rolling average smoothing if enabled
        if smooth:
            actual_series = actual_series.rolling(window=10).mean()
            predicted_series = predicted_series.rolling(window=10).mean()

        # Zoom in if specified
        if zoom_last_n and len(actual_series) > zoom_last_n:
            actual_series = actual_series[-zoom_last_n:]
            predicted_series = predicted_series[-zoom_last_n:]

        # Plot
        plt.plot(actual_series, label='Actual (Smoothed)' if smooth else 'Actual')
        plt.plot(predicted_series, label='Predicted (Smoothed)' if smooth else 'Predicted')

        plt.title(f'{title} - {feature_names[i]}')
        plt.xlabel('Time Step (Countries Sampling)')
        plt.ylabel('Change (%)')
        plt.legend()
        plt.grid(True)

    plt.tight_layout()
    plt.show()

# IMPROVEMENT 9: Enhanced visualization for model comparison
def plot_training_history(history):
    metrics = ['loss', 'mae', 'mse', 'root_mean_squared_error']
    fig, axes = plt.subplots(2, 2, figsize=(16, 10))
    axes = axes.flat

    for i, metric in enumerate(metrics):
        ax = axes[i]
        ax.plot(history.history[metric], label=f'Training {metric}')
        ax.plot(history.history[f'val_{metric}'], label=f'Validation {metric}')
        ax.set_title(f'Training and Validation {metric.upper()}')
        ax.set_xlabel('Epochs')
        ax.set_ylabel(metric.upper())
        ax.legend()
        ax.grid(True)

    plt.tight_layout()
    plt.show()

# Plot improved training history visualization
plot_training_history(history)

# IMPROVEMENT 10: Enhanced country-specific prediction visualization
def plot_predictions_per_country(y_true, y_pred, countries, dates, feature_names, save_dir=None):
    unique_countries = np.unique(countries)

    for country in unique_countries:
        indices = np.where(countries == country)[0]
        if len(indices) < 5:  # Skip countries with very few test points
            continue

        actual = y_true[indices]
        predicted = y_pred[indices]
        country_dates = dates[indices]

        fig, axs = plt.subplots(len(feature_names), 1, figsize=(12, 4 * len(feature_names)))
        if len(feature_names) == 1:
            axs = [axs]

        for i, feature in enumerate(feature_names):
            # Calculate error metrics for this feature
            feature_mse = mean_squared_error(actual[:, i], predicted[:, i])
            feature_mae = mean_absolute_error(actual[:, i], predicted[:, i])
            feature_rmse = np.sqrt(feature_mse)

            axs[i].plot(actual[:, i], label='Actual', color='blue', marker='o', markersize=4)
            axs[i].plot(predicted[:, i], label='Predicted', color='orange', marker='x', markersize=4)

            # Add error bands
            axs[i].fill_between(
                range(len(actual[:, i])),
                predicted[:, i] - feature_mae,
                predicted[:, i] + feature_mae,
                color='orange', alpha=0.2, label='±MAE Range'
            )

            axs[i].set_title(f'{feature} - {country} (RMSE: {feature_rmse:.4f}, MAE: {feature_mae:.4f})')
            axs[i].set_ylabel('Percentage Change')
            axs[i].set_xlabel('Time Steps')
            axs[i].legend()
            axs[i].grid(True)

        plt.tight_layout()

        if save_dir:
            os.makedirs(save_dir, exist_ok=True)
            plt.savefig(f"{save_dir}/{country.replace(' ', '_')}_predicted_vs_actual.png")
            plt.close()
        else:
            plt.show()

# Plot country-specific predictions
plot_predictions_per_country(
    y_test_original,
    y_pred_original,
    country_names_test,
    dates_test,
    feature_names,
    save_dir="improved_prediction_plots"
)

# IMPROVEMENT 11: Feature importance analysis
def analyze_feature_importance():
    """
    Create a simple feature importance analysis by training models with one feature removed at a time
    """
    base_rmse = rmse
    importance_scores = []

    for i in range(X_train.shape[2]):
        # Create a copy with one feature zeroed out
        X_train_modified = X_train.copy()
        X_test_modified = X_test.copy()

        X_train_modified[:, :, i] = 0
        X_test_modified[:, :, i] = 0

        # Train a smaller model for quicker evaluation
        temp_model = create_enhanced_lstm_model(input_shape, output_shape)
        temp_model.compile(optimizer=Adam(learning_rate=0.0005), loss=Huber(delta=0.5), metrics=['mae'])

        # Use fewer epochs for speed
        temp_model.fit(
            X_train_modified, y_train,
            epochs=150,
            batch_size=32,
            validation_split=0.2,
            callbacks=[early_stopping],
            verbose=0
        )

        # Evaluate
        temp_pred = temp_model.predict(X_test_modified)

        # Convert to original scale
        temp_pred_original = np.zeros_like(temp_pred)
        for i, country in enumerate(country_names_test):
            if country in scalers:
                temp_pred_original[i] = scalers[country].inverse_transform(temp_pred[i].reshape(1, -1))

        # Calculate metrics
        temp_mse = mean_squared_error(y_test_original, temp_pred_original)
        temp_rmse = math.sqrt(temp_mse)

# Plot predictions
plot_predictions(y_test_original, y_pred_original, feature_names, 'LSTM Predictions vs Actual', smooth=True, zoom_last_n=100)

"""Why it's limited to 3.0 (approximately):

The loop that generates the plots has this condition:

if len(indices) < 20:  # Use 20 as the threshold
    continue
Use code with caution
This condition skips countries with fewer than 20 data points. It's possible that the countries included in your plots have only a few data points after applying this filter, resulting in a limited x-axis range.
"""

import os
import matplotlib.pyplot as plt
import glob
from IPython.display import Image, display
import numpy as np  # Import numpy for np.unique()

# Create folder to save plots
output_dir = "plots"
os.makedirs(output_dir, exist_ok=True)

# Define unique_countries using country_names_test
unique_countries = np.unique(country_names_test) # Get unique countries from country_names_test

# Loop to plot and save
for i, country in enumerate(unique_countries):
    try:
        # Check if y_test_inverse and predictions_inverse have enough elements
        if i < len(y_test_original) and i < len(y_pred_original):
            actual = y_test_original[i].flatten()
            predicted = y_pred_original[i].flatten()
            time_steps = np.arange(len(actual))  # Explicit x-axis

            plt.figure(figsize=(12, 4))  # Wider frame
            plt.plot(time_steps, actual, label='Actual')
            plt.plot(time_steps, predicted, label='Predicted')
            plt.title(f'{country} - Gasoline & Diesel Price % Change')
            plt.xlabel('Time Step')
            plt.ylabel('Percentage Change')
            plt.legend()
            plt.tight_layout()


            # Save the plot
            filename = f"{country.replace(' ', '_')}_prediction_plot.png"
            plt.savefig(os.path.join(output_dir, filename))

            # Show plot inline
            plt.show()
        else:
            print(f"Skipping {country}: index out of bounds for actual/predicted values")
    except IndexError:
        print(f"Skipping {country}: index out of bounds")

# Display all saved plots at the end
for file in sorted(glob.glob("plots/*.png")):
    display(Image(filename=file))

# Save the prediction table to a CSV file
prediction_table.to_csv('predicted_fuel_price_changes.csv', index=False)

print("Predicted fuel price changes saved to 'predicted_fuel_price_changes.csv'")

!pip install dash plotly pandas numpy scikit-learn dash-bootstrap-components

!pip install jupyter_dash

import pandas as pd
import numpy as np
import requests
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import dash
from dash import dcc, html, Input, Output, State, dash_table
import dash_bootstrap_components as dbc
from datetime import datetime, timedelta
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
import base64
import io
import warnings
warnings.filterwarnings('ignore')

# Assume 'data', 'y_test_original', 'y_pred_original', 'country_names_test', 'feature_names' are already defined from your previous code
# Assume 'scalers' dictionary is also available from your previous code

class FuelPriceDashboard:
    def __init__(self, historical_data_for_model, y_test_original, y_pred_original, country_names_test, feature_names, scalers):
        # Data for modeling (already heavily preprocessed: log1p, pct_change, scaled)
        self.historical_data_for_model = historical_data_for_model.copy()
        # Ensure Date column in historical_data_for_model is datetime
        if not pd.api.types.is_datetime64_any_dtype(self.historical_data_for_model['Date']):
            self.historical_data_for_model['Date'] = pd.to_datetime(self.historical_data_for_model['Date'], dayfirst=True, errors='coerce')


        self.y_test_original = y_test_original
        self.y_pred_original = y_pred_original
        self.country_names_test = country_names_test
        self.feature_names = feature_names # This refers to ['Gasoline\none week', ...]

        # It's important that scalers are associated with the 'historical_data_for_model' preprocessing
        self.scalers = scalers

        # --- Load and preprocess raw data specifically for display (Current Changes & Historical Plot) ---
        url = 'https://docs.google.com/spreadsheets/d/1SnQdV18e9GjKfX5JXNv7mHXTIzVifrQZ5g0gSr4kWSc/export?format=csv'
        raw_data_temp = pd.read_csv(url)

        columns_for_display = ['Gasoline\none week', 'Gasoline\nthree months', 'Diesel\none week', 'Diesel\nthree months']

        # Basic cleaning for display data: convert percentages to float, handle NaNs, parse date
        for col in columns_for_display:
            raw_data_temp[col].replace('', np.nan, inplace=True) # Replace empty strings with NaN
            # Convert to string first to ensure .str.replace() works, then to numeric
            raw_data_temp[col] = raw_data_temp[col].astype(str).str.replace('%', '', regex=False)
            raw_data_temp[col] = pd.to_numeric(raw_data_temp[col], errors='coerce')

        raw_data_temp['Date'] = pd.to_datetime(raw_data_temp['Date'], dayfirst=True, errors='coerce')

        # Fill NaNs for display data to ensure continuous lines in plots
        raw_data_temp.fillna(method='ffill', inplace=True)
        raw_data_temp.fillna(method='bfill', inplace=True)
        raw_data_temp.dropna(inplace=True) # Final drop if any rows still have NaNs

        self.raw_historical_data = raw_data_temp.sort_values(by=['Countries', 'Date']).reset_index(drop=True)
        # --- End of raw data loading for display ---

    def get_countries(self):
        """Get list of available countries from the raw data (for dropdown)."""
        return sorted(self.raw_historical_data['Countries'].unique())

    def get_current_price_changes(self, selected_country):
        """Get the latest actual price changes from the RAW GlobalPetrolPrice data for a country."""
        if selected_country and not self.raw_historical_data.empty:
            # Use raw_historical_data for current changes
            country_data = self.raw_historical_data[self.raw_historical_data['Countries'] == selected_country].copy()

            if not country_data.empty:
                country_data = country_data.sort_values('Date')
                latest_data = country_data.iloc[-1]  # Get the most recent row

                current_changes_data = []
                for feature in self.feature_names: # Use model's feature names to check in raw data
                    if feature in latest_data:
                        change_value = latest_data[feature]
                        fuel_display_name = feature.replace('\n', ' ').title()
                        current_changes_data.append({
                            'Fuel Type': fuel_display_name,
                            'Current Price Change (%)': f"{change_value:.2f}%", # Display raw percentage
                            'Last Updated': latest_data['Date'].strftime('%Y-%m-%d') if pd.notna(latest_data['Date']) else 'N/A'
                        })

                changes_df = pd.DataFrame(current_changes_data)
                return changes_df
        return pd.DataFrame()

    def create_forecast_model(self, country_data, fuel_type):
        """Create a simple forecast model using historical_data_for_model."""
        # This method receives country_data which is a slice from self.historical_data_for_model
        # So, it should already be properly preprocessed for modeling.
        if fuel_type not in self.feature_names:
            return None, None

        country_data = country_data.copy()
        # Ensure 'Date' column is datetime for sorting if it somehow lost its type after slicing
        if not pd.api.types.is_datetime64_any_dtype(country_data['Date']):
            country_data['Date'] = pd.to_datetime(country_data['Date'], dayfirst=True, errors='coerce')

        country_data = country_data.sort_values('Date')
        country_data['time_index'] = np.arange(len(country_data))

        if fuel_type not in country_data.columns:
             print(f"Warning: {fuel_type} not found in country data columns.")
             return None, None

        X = country_data[['time_index']]
        y = country_data[fuel_type]

        if len(X) < 5:
             return None, None

        model = LinearRegression()
        model.fit(X, y)

        return model, country_data

    def generate_forecasts(self, country, fuel_type, periods=7):
        """Generate price change forecasts using the simple model on historical_data_for_model."""
        if self.historical_data_for_model is None:
            return None

        country_data = self.historical_data_for_model[self.historical_data_for_model['Countries'] == country].copy()

        if len(country_data) == 0:
            return None

        model, processed_data = self.create_forecast_model(country_data, fuel_type)

        if model is None:
            return None

        last_time_index = processed_data['time_index'].iloc[-1]
        future_time_indices = np.arange(last_time_index + 1, last_time_index + 1 + periods).reshape(-1, 1)
        predicted_changes = model.predict(future_time_indices)

        forecasts = pd.DataFrame({
            'Days_Ahead': np.arange(1, periods + 1),
            'Predicted_Change': predicted_changes
        })

        return forecasts

    def is_short_term_fuel(self, fuel_type):
        """Check if fuel type is short-term (1 week)"""
        return 'one week' in fuel_type.lower()

    def is_long_term_fuel(self, fuel_type):
        """Check if fuel type is long-term (3 months)"""
        return 'three months' in fuel_type.lower()


# Initialize the dashboard with the data from the notebook
# The 'data' variable from your notebook should still be the one *fully preprocessed for the model*.
# The FuelPriceDashboard constructor will now internally load and clean 'raw_historical_data' for display.
dashboard = FuelPriceDashboard(data, y_test_original, y_pred_original, country_names_test, feature_names, scalers)

# Initialize Dash app
from jupyter_dash import JupyterDash
app = JupyterDash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])

# Enhanced CSS (from your original code)
app.index_string = '''
<!DOCTYPE html>
<html>
    <head>
        {%metas%}
        <title>Fuel Price Analysis Dashboard</title>
        {%favicon%}
        {%css%}
        <style>
            body {
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                min-height: 100vh;
            }
            .main-header {
                text-align: center;
                color: white;
                margin-bottom: 30px;
                font-weight: bold;
                text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
                font-size: 2.5rem;
            }
            .card {
                background: rgba(255, 255, 255, 0.95);
                backdrop-filter: blur(10px);
                border: none;
                border-radius: 15px;
                box-shadow: 0 8px 32px rgba(0, 0, 0, 0.1);
                margin-bottom: 20px;
                transition: transform 0.3s ease;
            }
            .card:hover {
                transform: translateY(-5px);
            }
            .card-header {
                background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                color: white;
                border-radius: 15px 15px 0 0 !important;
                font-weight: bold;
                font-size: 1.1rem;
                padding: 15px 20px;
                border: none;
            }
            .metric-card {
                background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%);
                color: white;
                padding: 20px;
                border-radius: 15px;
                margin: 10px 0;
                box-shadow: 0 6px 20px rgba(0, 0, 0, 0.15);
                transition: transform 0.3s ease;
            }
            .metric-card:hover {
                transform: scale(1.02);
            }
            .forecast-container {
                background: rgba(255, 255, 255, 0.98);
                padding: 25px;
                border-radius: 15px;
                box-shadow: 0 4px 20px rgba(0,0,0,0.1);
                margin: 20px 0;
                border: 1px solid rgba(255, 255, 255, 0.2);
            }
            .forecast-section {
                background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%);
                padding: 20px;
                border-radius: 12px;
                margin: 15px 0;
                box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            }
            .forecast-section h6 {
                color: #2c3e50;
                font-weight: bold;
                margin-bottom: 15px;
                font-size: 1.1rem;
            }
            .short-term-section {
                background: linear-gradient(135deg, #a8edea 0%, #fed6e3 100%);
            }
            .long-term-section {
                background: linear-gradient(135deg, #d299c2 0%, #fef9d7 100%);
            }
            .disclaimer {
                background: rgba(255, 255, 255, 0.9);
                padding: 20px;
                border-radius: 15px;
                border-left: 5px solid #17a2b8;
                font-size: 14px;
                color: #495057;
                margin-top: 30px;
                box-shadow: 0 4px 15px rgba(0,0,0,0.1);
            }
            .dash-table-container {
                border-radius: 10px;
                overflow: hidden;
                box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            }
            .Select-control {
                border-radius: 10px !important;
                border: 2px solid #e9ecef !important;
                transition: all 0.3s ease !important;
            }
            .Select-control:hover {
                border-color: #667eea !important;
            }
            .container-fluid {
                padding: 20px;
            }
            .positive-change {
                color: #28a745;
                font-weight: bold;
            }
            .negative-change {
                color: #dc3545;
                font-weight: bold;
            }
            .neutral-change {
                color: #6c757d;
                font-weight: bold;
            }
        </style>
    </head>
    <body>
        {%app_entry%}
        <footer>
            {%config%}
            {%scripts%}
            {%renderer%}
        </footer>
    </body>
</html>
'''

# Enhanced App layout (from your original code)
app.layout = dbc.Container([
    # Header
    dbc.Row([
        dbc.Col([
            html.H1("⛽ Fuel Price Analysis Dashboard", className="main-header"),
            html.P("Advanced Analytics & Forecasting Platform",
                   style={'text-align': 'center', 'color': 'white', 'font-size': '1.2rem', 'margin-bottom': '30px'})
        ])
    ]),

    # Country Selection
    dbc.Row([
        dbc.Col([
            dbc.Card([
                dbc.CardHeader("🌍 Select Country for Analysis"),
                dbc.CardBody([
                    dcc.Dropdown(
                        id='country-dropdown',
                        options=[{'label': f"🏳️ {country}", 'value': country} for country in dashboard.get_countries()],
                        placeholder="Choose a country to analyze...",
                        style={'width': '100%', 'fontSize': '16px'}
                    )
                ])
            ])
        ], width=12)
    ], className="mb-4"),

    # Current Price Changes Table
    dbc.Row([
        dbc.Col([
            dbc.Card([
                dbc.CardHeader("📈 Current Actual Price Changes (Latest Available Data)"),
                dbc.CardBody([
                    html.Div(id='current-changes-table', className="dash-table-container")
                ])
            ])
        ], width=12)
    ], className="mb-4"),

    # Historical Chart
    dbc.Row([
        dbc.Col([
            dbc.Card([
                dbc.CardHeader("📊 Historical Fuel Price Trends"),
                dbc.CardBody([
                    dcc.Graph(id='historical-chart', config={'displayModeBar': True})
                ])
            ])
        ], width=12)
    ], className="mb-4"),

    # Forecast Chart and Tables
    dbc.Row([
        dbc.Col([
            dbc.Card([
                dbc.CardHeader("🔮 Fuel Price Change Forecasts"),
                dbc.CardBody([
                    dcc.Graph(id='forecast-chart', config={'displayModeBar': True}),

                    # Short-term Forecasts Section
                    html.Div([
                        html.H5("📅 Short-term Forecasts (7 Days)",
                               style={'color': '#2c3e50', 'margin-bottom': '20px', 'font-weight': 'bold'}),
                        html.Div(id='forecast-short-table', className="short-term-section forecast-section")
                    ], className="forecast-container"),

                    # Long-term Forecasts Section
                    html.Div([
                        html.H5("📈 Long-term Forecasts (90 Days)",
                               style={'color': '#2c3e50', 'margin-bottom': '20px', 'font-weight': 'bold'}),
                        html.Div(id='forecast-long-table', className="long-term-section forecast-section")
                    ], className="forecast-container")
                ])
            ])
        ], width=12)
    ], className="mb-4"),

    # Footer
    dbc.Row([
        dbc.Col([
            html.Div([
                html.Strong("📊 Data Source: "), "Global Fuel Price Benchmark Database", html.Br(),
                html.Strong("⚠️ Disclaimer: "), "Forecasts are algorithmic estimates based on historical patterns. Results may not reflect actual future prices. This dashboard is designed for analytical purposes and should not be used for financial decision-making without additional research.",
                html.Br(), html.Br(),
                html.Small("© 2025 Fuel Price Analytics Dashboard - Advanced ML Forecasting Platform")
            ], className="disclaimer")
        ])
    ])

], fluid=True)

# Modified callback with improved table separation and data sourcing
@app.callback(
    [Output('current-changes-table', 'children'),
     Output('historical-chart', 'figure'),
     Output('forecast-chart', 'figure'),
     Output('forecast-short-table', 'children'),
     Output('forecast-long-table', 'children')],
    Input('country-dropdown', 'value')
)
def update_dashboard(selected_country):
    # Default empty outputs for initial load or no country selected
    empty_fig = go.Figure()
    empty_fig.update_layout(
        title="Please select a country to view analysis",
        paper_bgcolor='rgba(0,0,0,0)',
        plot_bgcolor='rgba(0,0,0,0)',
        font=dict(color='#2c3e50'),
        xaxis={'visible': False},
        yaxis={'visible': False},
        annotations=[{
            'text': "🔍 Select a country to begin analysis",
            'xref': "paper",
            'yref': "paper",
            'x': 0.5,
            'y': 0.5,
            'xanchor': 'center',
            'yanchor': 'middle',
            'showarrow': False,
            'font': {'size': 18, 'color': '#6c757d'}
        }]
    )

    if not selected_country:
        return "", empty_fig, empty_fig, "", ""

    try:
        # Current Actual Price Changes from raw data
        current_changes_df = dashboard.get_current_price_changes(selected_country)

        if not current_changes_df.empty:
            current_changes_table = dash_table.DataTable(
                data=current_changes_df.to_dict('records'),
                columns=[{"name": i, "id": i} for i in current_changes_df.columns],
                style_cell={
                    'textAlign': 'center',
                    'padding': '12px',
                    'fontSize': '14px',
                    'fontFamily': 'Segoe UI'
                },
                style_header={
                    'backgroundColor': '#667eea',
                    'color': 'white',
                    'fontWeight': 'bold',
                    'fontSize': '16px'
                },
                style_data_conditional=[
                    {
                        'if': {'row_index': i, 'column_id': 'Current Price Change (%)'},
                        'color': '#28a745' if float(current_changes_df.iloc[i]['Current Price Change (%)'].replace('%', '')) > 0 else (
                            '#dc3545' if float(current_changes_df.iloc[i]['Current Price Change (%)'].replace('%', '')) < 0 else '#6c757d'
                        ),
                        'fontWeight': 'bold'
                    } for i in range(len(current_changes_df))
                ]
            )
        else:
            current_changes_table = html.Div(
                "No current price change data available for this country.",
                style={'color': '#6c757d', 'textAlign': 'center', 'padding': '20px'}
            )

        # Historical Chart from raw data
        country_historical_data = dashboard.raw_historical_data[dashboard.raw_historical_data['Countries'] == selected_country]

        historical_fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=[
                '⛽ Gasoline (1 Week)',
                '⛽ Gasoline (3 Months)',
                '🚛 Diesel (1 Week)',
                '🚛 Diesel (3 Months)'
            ],
            vertical_spacing=0.15,
            horizontal_spacing=0.1
        )

        colors = ['#667eea', '#764ba2', '#11998e', '#38ef7d']

        for i, feature in enumerate(dashboard.feature_names):
            row = (i // 2) + 1
            col = (i % 2) + 1
            historical_fig.add_trace(
                go.Scatter(
                    x=country_historical_data['Date'],
                    y=country_historical_data[feature], # Plotting raw percentage values
                    mode='lines+markers',
                    name=feature,
                    line=dict(width=3, color=colors[i]),
                    marker=dict(size=6, color=colors[i])
                ),
                row=row, col=col
            )

        historical_fig.update_layout(
            title=f"📊 Historical Fuel Price Changes - {selected_country}",
            height=700,
            showlegend=False,
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            font=dict(color='#2c3e50', size=12)
        )

        historical_fig.update_xaxes(title_text="Date", showgrid=True, gridcolor='rgba(0,0,0,0.1)')
        historical_fig.update_yaxes(title_text="Percentage Change (%)", showgrid=True, gridcolor='rgba(0,0,0,0.1)')

        # Forecast Chart and Tables (these still use the model's preprocessed data and predictions)
        short_forecasts = {}
        long_forecasts = {}
        forecast_fig = make_subplots(
            rows=2, cols=2,
            subplot_titles=[f'🔮 {feat} Forecast' for feat in dashboard.feature_names],
            vertical_spacing=0.15,
            horizontal_spacing=0.1
        )

        for i, feature in enumerate(dashboard.feature_names):
            short_forecast = dashboard.generate_forecasts(selected_country, feature, 7)
            long_forecast = dashboard.generate_forecasts(selected_country, feature, 90)

            if short_forecast is not None:
                short_forecasts[feature] = short_forecast.round(2)
                row = (i // 2) + 1
                col = (i % 2) + 1
                forecast_fig.add_trace(
                    go.Scatter(
                        x=short_forecast['Days_Ahead'],
                        y=short_forecast['Predicted_Change'],
                        mode='lines+markers',
                        name=feature,
                        line=dict(width=3, color=colors[i]),
                        marker=dict(size=8, color=colors[i])
                    ),
                    row=row, col=col
                )
            if long_forecast is not None:
                long_forecasts[feature] = long_forecast.round(2)

        forecast_fig.update_layout(
            title=f"🔮 Fuel Price Change Forecasts - {selected_country}",
            height=700,
            showlegend=False,
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            font=dict(color='#2c3e50', size=12)
        )
        forecast_fig.update_xaxes(title_text="Days Ahead", showgrid=True, gridcolor='rgba(0,0,0,0.1)')
        forecast_fig.update_yaxes(title_text="Predicted Change (%)", showgrid=True, gridcolor='rgba(0,0,0,0.1)')

        short_term_data = []
        long_term_data = []

        for feature in dashboard.feature_names:
            if dashboard.is_short_term_fuel(feature):
                if feature in short_forecasts and not short_forecasts[feature].empty:
                    predicted_change_7day = short_forecasts[feature]['Predicted_Change'].iloc[-1]
                    fuel_name = "Gasoline" if "Gasoline" in feature else "Diesel"
                    short_term_data.append({
                        'Fuel Type': f"{fuel_name} (1 Week)",
                        'Predicted Change After 7 Days (%)': f"{predicted_change_7day:.2f}%"
                    })

            elif dashboard.is_long_term_fuel(feature):
                if feature in long_forecasts and not long_forecasts[feature].empty:
                    predicted_change_90day = long_forecasts[feature]['Predicted_Change'].iloc[-1]
                    fuel_name = "Gasoline" if "Gasoline" in feature else "Diesel"
                    long_term_data.append({
                        'Fuel Type': f"{fuel_name} (3 Months)",
                        'Predicted Change After 90 Days (%)': f"{predicted_change_90day:.2f}%"
                    })

        short_table_html = html.Div("No short-term forecast data available.", style={'color': '#6c757d'})
        if short_term_data:
            short_table_html = dash_table.DataTable(
                data=short_term_data,
                columns=[{"name": i, "id": i} for i in ['Fuel Type', 'Predicted Change After 7 Days (%)']],
                style_cell={'textAlign': 'center', 'padding': '12px', 'fontSize': '14px'},
                style_header={'backgroundColor': '#a8edea', 'fontWeight': 'bold', 'color': '#2c3e50'},
                style_data_conditional=[
                    {
                        'if': {'column_id': 'Predicted Change After 7 Days (%)'},
                        'color': '#28a745',
                        'fontWeight': 'bold'
                    }
                ]
            )

        long_table_html = html.Div("No long-term forecast data available.", style={'color': '#6c757d'})
        if long_term_data:
            long_table_html = dash_table.DataTable(
                data=long_term_data,
                columns=[{"name": i, "id": i} for i in ['Fuel Type', 'Predicted Change After 90 Days (%)']],
                style_cell={'textAlign': 'center', 'padding': '12px', 'fontSize': '14px'},
                style_header={'backgroundColor': '#d299c2', 'fontWeight': 'bold', 'color': '#2c3e50'},
                style_data_conditional=[
                    {
                        'if': {'column_id': 'Predicted Change After 90 Days (%)'},
                        'color': '#dc3545',
                        'fontWeight': 'bold'
                    }
                ]
            )

        return current_changes_table, historical_fig, forecast_fig, short_table_html, long_table_html

    except Exception as e:
        print(f"Error in update_dashboard callback: {e}")
        error_message_fig = go.Figure()
        error_message_fig.update_layout(
            title="An error occurred",
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            font=dict(color='red'),
            xaxis={'visible': False},
            yaxis={'visible': False},
            annotations=[{
                'text': f"🚫 Error: {e}",
                'xref': "paper",
                'yref': "paper",
                'x': 0.5,
                'y': 0.5,
                'xanchor': 'center',
                'yanchor': 'middle',
                'showarrow': False,
                'font': {'size': 16, 'color': 'red'}
            }]
        )
        return html.Div(f"An error occurred: {e}", style={'color': 'red'}), error_message_fig, error_message_fig, "", ""

# Run the app
if __name__ == '__main__':
    app.run(debug=True, mode='inline')